{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritamgh/DLT-lab/blob/main/Week14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckCFPNXvem7K",
        "outputId": "b7331d62-f11c-44c2-d85f-2517db681b73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 48.3MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 157MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "ResNet                                   [1, 10]                   --\n",
            "├─Conv2d: 1-1                            [1, 64, 112, 112]         (9,408)\n",
            "├─BatchNorm2d: 1-2                       [1, 64, 112, 112]         (128)\n",
            "├─ReLU: 1-3                              [1, 64, 112, 112]         --\n",
            "├─MaxPool2d: 1-4                         [1, 64, 56, 56]           --\n",
            "├─Sequential: 1-5                        [1, 64, 56, 56]           --\n",
            "│    └─BasicBlock: 2-1                   [1, 64, 56, 56]           --\n",
            "│    │    └─Conv2d: 3-1                  [1, 64, 56, 56]           (36,864)\n",
            "│    │    └─BatchNorm2d: 3-2             [1, 64, 56, 56]           (128)\n",
            "│    │    └─ReLU: 3-3                    [1, 64, 56, 56]           --\n",
            "│    │    └─Conv2d: 3-4                  [1, 64, 56, 56]           (36,864)\n",
            "│    │    └─BatchNorm2d: 3-5             [1, 64, 56, 56]           (128)\n",
            "│    │    └─ReLU: 3-6                    [1, 64, 56, 56]           --\n",
            "│    └─BasicBlock: 2-2                   [1, 64, 56, 56]           --\n",
            "│    │    └─Conv2d: 3-7                  [1, 64, 56, 56]           (36,864)\n",
            "│    │    └─BatchNorm2d: 3-8             [1, 64, 56, 56]           (128)\n",
            "│    │    └─ReLU: 3-9                    [1, 64, 56, 56]           --\n",
            "│    │    └─Conv2d: 3-10                 [1, 64, 56, 56]           (36,864)\n",
            "│    │    └─BatchNorm2d: 3-11            [1, 64, 56, 56]           (128)\n",
            "│    │    └─ReLU: 3-12                   [1, 64, 56, 56]           --\n",
            "├─Sequential: 1-6                        [1, 128, 28, 28]          --\n",
            "│    └─BasicBlock: 2-3                   [1, 128, 28, 28]          --\n",
            "│    │    └─Conv2d: 3-13                 [1, 128, 28, 28]          (73,728)\n",
            "│    │    └─BatchNorm2d: 3-14            [1, 128, 28, 28]          (256)\n",
            "│    │    └─ReLU: 3-15                   [1, 128, 28, 28]          --\n",
            "│    │    └─Conv2d: 3-16                 [1, 128, 28, 28]          (147,456)\n",
            "│    │    └─BatchNorm2d: 3-17            [1, 128, 28, 28]          (256)\n",
            "│    │    └─Sequential: 3-18             [1, 128, 28, 28]          (8,448)\n",
            "│    │    └─ReLU: 3-19                   [1, 128, 28, 28]          --\n",
            "│    └─BasicBlock: 2-4                   [1, 128, 28, 28]          --\n",
            "│    │    └─Conv2d: 3-20                 [1, 128, 28, 28]          (147,456)\n",
            "│    │    └─BatchNorm2d: 3-21            [1, 128, 28, 28]          (256)\n",
            "│    │    └─ReLU: 3-22                   [1, 128, 28, 28]          --\n",
            "│    │    └─Conv2d: 3-23                 [1, 128, 28, 28]          (147,456)\n",
            "│    │    └─BatchNorm2d: 3-24            [1, 128, 28, 28]          (256)\n",
            "│    │    └─ReLU: 3-25                   [1, 128, 28, 28]          --\n",
            "├─Sequential: 1-7                        [1, 256, 14, 14]          --\n",
            "│    └─BasicBlock: 2-5                   [1, 256, 14, 14]          --\n",
            "│    │    └─Conv2d: 3-26                 [1, 256, 14, 14]          (294,912)\n",
            "│    │    └─BatchNorm2d: 3-27            [1, 256, 14, 14]          (512)\n",
            "│    │    └─ReLU: 3-28                   [1, 256, 14, 14]          --\n",
            "│    │    └─Conv2d: 3-29                 [1, 256, 14, 14]          (589,824)\n",
            "│    │    └─BatchNorm2d: 3-30            [1, 256, 14, 14]          (512)\n",
            "│    │    └─Sequential: 3-31             [1, 256, 14, 14]          (33,280)\n",
            "│    │    └─ReLU: 3-32                   [1, 256, 14, 14]          --\n",
            "│    └─BasicBlock: 2-6                   [1, 256, 14, 14]          --\n",
            "│    │    └─Conv2d: 3-33                 [1, 256, 14, 14]          (589,824)\n",
            "│    │    └─BatchNorm2d: 3-34            [1, 256, 14, 14]          (512)\n",
            "│    │    └─ReLU: 3-35                   [1, 256, 14, 14]          --\n",
            "│    │    └─Conv2d: 3-36                 [1, 256, 14, 14]          (589,824)\n",
            "│    │    └─BatchNorm2d: 3-37            [1, 256, 14, 14]          (512)\n",
            "│    │    └─ReLU: 3-38                   [1, 256, 14, 14]          --\n",
            "├─Sequential: 1-8                        [1, 512, 7, 7]            --\n",
            "│    └─BasicBlock: 2-7                   [1, 512, 7, 7]            --\n",
            "│    │    └─Conv2d: 3-39                 [1, 512, 7, 7]            (1,179,648)\n",
            "│    │    └─BatchNorm2d: 3-40            [1, 512, 7, 7]            (1,024)\n",
            "│    │    └─ReLU: 3-41                   [1, 512, 7, 7]            --\n",
            "│    │    └─Conv2d: 3-42                 [1, 512, 7, 7]            (2,359,296)\n",
            "│    │    └─BatchNorm2d: 3-43            [1, 512, 7, 7]            (1,024)\n",
            "│    │    └─Sequential: 3-44             [1, 512, 7, 7]            (132,096)\n",
            "│    │    └─ReLU: 3-45                   [1, 512, 7, 7]            --\n",
            "│    └─BasicBlock: 2-8                   [1, 512, 7, 7]            --\n",
            "│    │    └─Conv2d: 3-46                 [1, 512, 7, 7]            (2,359,296)\n",
            "│    │    └─BatchNorm2d: 3-47            [1, 512, 7, 7]            (1,024)\n",
            "│    │    └─ReLU: 3-48                   [1, 512, 7, 7]            --\n",
            "│    │    └─Conv2d: 3-49                 [1, 512, 7, 7]            (2,359,296)\n",
            "│    │    └─BatchNorm2d: 3-50            [1, 512, 7, 7]            (1,024)\n",
            "│    │    └─ReLU: 3-51                   [1, 512, 7, 7]            --\n",
            "├─AdaptiveAvgPool2d: 1-9                 [1, 512, 1, 1]            --\n",
            "├─Sequential: 1-10                       [1, 10]                   --\n",
            "│    └─Dropout: 2-9                      [1, 512]                  --\n",
            "│    └─Linear: 2-10                      [1, 10]                   5,130\n",
            "==========================================================================================\n",
            "Total params: 11,181,642\n",
            "Trainable params: 5,130\n",
            "Non-trainable params: 11,176,512\n",
            "Total mult-adds (Units.GIGABYTES): 1.81\n",
            "==========================================================================================\n",
            "Input size (MB): 0.60\n",
            "Forward/backward pass size (MB): 39.74\n",
            "Params size (MB): 44.73\n",
            "Estimated Total Size (MB): 85.07\n",
            "==========================================================================================\n",
            "Epoch 1/5 | val_loss=0.7023 | val_acc=76.37% | time=105.0s\n",
            "Epoch 2/5 | val_loss=0.6327 | val_acc=78.72% | time=104.4s\n",
            "Epoch 3/5 | val_loss=0.6006 | val_acc=79.65% | time=107.7s\n",
            "Epoch 4/5 | val_loss=0.5957 | val_acc=79.47% | time=103.7s\n",
            "Epoch 5/5 | val_loss=0.5881 | val_acc=79.87% | time=106.7s\n",
            "Done. Best Val Acc (frozen backbone): 79.87%\n",
            "[FT] Epoch 1/3 | val_loss=0.3267 | val_acc=88.60%\n",
            "[FT] Epoch 2/3 | val_loss=0.2760 | val_acc=91.04%\n",
            "[FT] Epoch 3/3 | val_loss=0.2866 | val_acc=90.60%\n",
            "Transfer learning complete.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Lab 14: Transfer Learning - Feature Extractor on CIFAR-10\n",
        "# ==========================================================\n",
        "!pip -q install torch torchvision torchinfo\n",
        "\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchinfo import summary\n",
        "from time import time\n",
        "\n",
        "torch.manual_seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# --- Data (CIFAR-10 -> 224, ImageNet stats)\n",
        "img_size = 224\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "\n",
        "weights18 = models.ResNet18_Weights.IMAGENET1K_V1\n",
        "mean, std = weights18.meta.get('mean', (0.485,0.456,0.406)), weights18.meta.get('std', (0.229,0.224,0.225))\n",
        "\n",
        "tf_train = transforms.Compose([\n",
        "    transforms.Resize((img_size,img_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(img_size, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "tf_val = transforms.Compose([\n",
        "    transforms.Resize((img_size,img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(\"/content/data\", train=True, download=True, transform=tf_train)\n",
        "valset   = datasets.CIFAR10(\"/content/data\", train=False, download=True, transform=tf_val)\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# --- Model\n",
        "backbone = models.resnet18(weights=weights18)\n",
        "for p in backbone.parameters():\n",
        "    p.requires_grad = False  # freeze all\n",
        "\n",
        "in_features = backbone.fc.in_features\n",
        "backbone.fc = nn.Sequential(\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(in_features, num_classes)\n",
        ")\n",
        "model = backbone.to(device).train()\n",
        "print(summary(model, input_size=(1,3,img_size,img_size), verbose=0))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n",
        "epochs = 5  # increase for stronger results\n",
        "\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    correct, total, val_loss = 0, 0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            val_loss += loss.item()*x.size(0)\n",
        "            pred = logits.argmax(1)\n",
        "            correct += (pred==y).sum().item()\n",
        "            total += y.size(0)\n",
        "    model.train()\n",
        "    return val_loss/total, correct/total\n",
        "\n",
        "best_acc = 0.0\n",
        "for ep in range(1, epochs+1):\n",
        "    t0 = time()\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    vloss, vacc = evaluate()\n",
        "    best_acc = max(best_acc, vacc)\n",
        "    print(f\"Epoch {ep}/{epochs} | val_loss={vloss:.4f} | val_acc={vacc*100:.2f}% | time={(time()-t0):.1f}s\")\n",
        "\n",
        "print(f\"Done. Best Val Acc (frozen backbone): {best_acc*100:.2f}%\")\n",
        "\n",
        "# --- Optional: Fine-tune last block + head\n",
        "for m in [model.layer4, model.fc]:\n",
        "    for p in m.parameters(): p.requires_grad = True\n",
        "\n",
        "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-4)\n",
        "epochs_ft = 3\n",
        "for ep in range(1, epochs_ft+1):\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(x), y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    vloss, vacc = evaluate()\n",
        "    print(f\"[FT] Epoch {ep}/{epochs_ft} | val_loss={vloss:.4f} | val_acc={vacc*100:.2f}%\")\n",
        "\n",
        "print(\"Transfer learning complete.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPhld/0jxpX8XDFPjDzczTc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}